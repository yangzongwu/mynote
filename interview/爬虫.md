### urllib 和 urllib2 的区别？
* urllib 和urllib2都是接受URL请求的相关模块，但是urllib2可以接受一个Request类的实例来设置URL请求的headers，urllib仅可以接受URL。urllib不可以伪装你的User-Agent字符串。
* urllib提供urlencode()方法用来GET查询字符串的产生，而urllib2没有。这是为何urllib常和urllib2一起使用的原因。
### 列举网络爬虫所用到的网络数据包，解析包
* 网络数据包 urllib、urllib2、requests
* 解析包 re、xpath、beautiful soup、lxml
### 简述一下爬虫的步骤？
* 确定需求；
* 确定资源；
* 通过url获取网站的返回数据；
* 定位数据；
* 存储数据。
### 遇到反爬机制怎么处理？
* headers方向 判断User-Agent、判断Referer、判断Cookie。 将浏览器的headers信息全部添加进去 
### 常见的HTTP方法有哪些？
* GET：请求指定的页面信息，返回实体主体；
* HEAD:类似于get请求，只不过返回的响应中没有具体的内容，用于捕获报头；
* POST：向指定资源提交数据进行处理请求(比如表单提交或者上传文件)，。数据被包含在请求体中。
* PUT:从客户端向服务端传送数据取代指定的文档的内容；
* DELETE：请求删除指定的页面；
* CONNNECT：HTTP1.1协议中预留给能够将连接方式改为管道方式的代理服务器；
* OPTIONS:允许客户端查看服务器的性能； TRACE：回显服务器的请求，主要用于测试或者诊断。
### 遇到的反爬虫策略以及解决方法?
* 通过headers反爬虫：自定义headers，添加网页中的headers数据。
* 基于用户行为的反爬虫(封IP)：可以使用多个代理IP爬取或者将爬取的频率降低。
* 动态网页反爬虫(JS或者Ajax请求数据)：动态网页可以使用 selenium + phantomjs 抓取。
* 对部分数据加密处理(数据乱码):找到加密方法进行逆向推理。
### 如果让你来防范网站爬虫，你应该怎么来提高爬取的难度 ？
* 判断headers的User-Agent；
* 检测同一个IP的访问频率；
* 数据通过Ajax获取；
* 爬取行为是对页面的源文件爬取，如果要爬取静态网页的html代码，可以使用jquery去模仿写html。